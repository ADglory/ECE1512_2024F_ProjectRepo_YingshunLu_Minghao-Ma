{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPEHlga4U7L0",
        "outputId": "699e4c18-f034-42b5-921d-dc7bf6b0a92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VICO-UoE/DatasetCondensation\n",
        "%cd DatasetCondensation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twcN5LTMVWzV",
        "outputId": "0afd4f4b-4a81-4267-9ea7-fbac7b419763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DatasetCondensation'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 271 (delta 126), reused 74 (delta 74), pack-reused 133 (from 1)\u001b[K\n",
            "Receiving objects: 100% (271/271), 4.54 MiB | 19.53 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "/content/DatasetCondensation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8draq7iVZxm",
        "outputId": "8ee6fa40-efd8-494c-ca19-11d4801ab21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.15.1 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.15.1.zip (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==1.1.0 (from -r requirements.txt (line 2))\n",
            "  Downloading scipy-1.1.0.tar.gz (15.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.2.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.2.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# download MNIST dataset\n",
        "mnist_data = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s42Ng_g7VeSB",
        "outputId": "7a135b59-2b5e-4165-ea7d-66969f47ada3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 899kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.04MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataset MNIST --method DM --ipc 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmMXG02zVqYX",
        "outputId": "e77119d7-27f1-4ccd-973a-8b2445c9bd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_it_pool:  [0, 500, 1000]\n",
            "\n",
            "================== Exp 0 ==================\n",
            " \n",
            "Hyper-parameters: \n",
            " {'method': 'DM', 'dataset': 'MNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 20, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7de36d1fd9c0>, 'dsa': False}\n",
            "Evaluation model pool:  ['ConvNet']\n",
            "class c = 0: 5923 real images\n",
            "class c = 1: 6742 real images\n",
            "class c = 2: 5958 real images\n",
            "class c = 3: 6131 real images\n",
            "class c = 4: 5842 real images\n",
            "class c = 5: 5421 real images\n",
            "class c = 6: 5918 real images\n",
            "class c = 7: 6265 real images\n",
            "class c = 8: 5851 real images\n",
            "class c = 9: 5949 real images\n",
            "real images channel 0, mean = -0.0001, std = 1.0000\n",
            "/content/DatasetCondensation/main.py:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
            "initialize synthetic data from random noise\n",
            "[2024-11-03 23:23:29] training begins\n",
            "-------------------------\n",
            "Evaluation\n",
            "model_train = ConvNet, model_eval = ConvNet, iteration = 0\n",
            "DC augmentation parameters: \n",
            " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
            "[2024-11-03 23:24:08] Evaluate_00: epoch = 1000 train time = 36 s train loss = 0.011867 train acc = 1.0000, test acc = 0.0943\n",
            "[2024-11-03 23:24:46] Evaluate_01: epoch = 1000 train time = 35 s train loss = 0.015994 train acc = 1.0000, test acc = 0.1153\n",
            "[2024-11-03 23:25:23] Evaluate_02: epoch = 1000 train time = 35 s train loss = 0.006754 train acc = 1.0000, test acc = 0.1453\n",
            "[2024-11-03 23:26:01] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.009939 train acc = 1.0000, test acc = 0.0762\n",
            "[2024-11-03 23:26:38] Evaluate_04: epoch = 1000 train time = 34 s train loss = 0.008773 train acc = 1.0000, test acc = 0.0859\n",
            "[2024-11-03 23:27:15] Evaluate_05: epoch = 1000 train time = 34 s train loss = 0.009646 train acc = 1.0000, test acc = 0.0296\n",
            "[2024-11-03 23:27:52] Evaluate_06: epoch = 1000 train time = 35 s train loss = 0.010515 train acc = 1.0000, test acc = 0.0811\n",
            "[2024-11-03 23:28:29] Evaluate_07: epoch = 1000 train time = 34 s train loss = 0.011801 train acc = 1.0000, test acc = 0.1026\n",
            "[2024-11-03 23:29:07] Evaluate_08: epoch = 1000 train time = 35 s train loss = 0.011601 train acc = 1.0000, test acc = 0.0547\n",
            "[2024-11-03 23:29:44] Evaluate_09: epoch = 1000 train time = 35 s train loss = 0.007835 train acc = 1.0000, test acc = 0.0850\n",
            "[2024-11-03 23:30:22] Evaluate_10: epoch = 1000 train time = 35 s train loss = 0.011320 train acc = 1.0000, test acc = 0.1140\n",
            "[2024-11-03 23:30:59] Evaluate_11: epoch = 1000 train time = 35 s train loss = 0.008788 train acc = 1.0000, test acc = 0.0847\n",
            "[2024-11-03 23:31:37] Evaluate_12: epoch = 1000 train time = 35 s train loss = 0.007590 train acc = 1.0000, test acc = 0.0716\n",
            "[2024-11-03 23:32:14] Evaluate_13: epoch = 1000 train time = 35 s train loss = 0.010688 train acc = 1.0000, test acc = 0.0988\n",
            "[2024-11-03 23:32:51] Evaluate_14: epoch = 1000 train time = 34 s train loss = 0.012900 train acc = 1.0000, test acc = 0.1350\n",
            "[2024-11-03 23:33:29] Evaluate_15: epoch = 1000 train time = 35 s train loss = 0.013129 train acc = 1.0000, test acc = 0.0661\n",
            "[2024-11-03 23:34:06] Evaluate_16: epoch = 1000 train time = 35 s train loss = 0.016028 train acc = 1.0000, test acc = 0.0656\n",
            "[2024-11-03 23:34:44] Evaluate_17: epoch = 1000 train time = 35 s train loss = 0.012058 train acc = 1.0000, test acc = 0.0536\n",
            "[2024-11-03 23:35:21] Evaluate_18: epoch = 1000 train time = 34 s train loss = 0.009164 train acc = 1.0000, test acc = 0.0657\n",
            "[2024-11-03 23:35:58] Evaluate_19: epoch = 1000 train time = 35 s train loss = 0.011086 train acc = 1.0000, test acc = 0.1449\n",
            "Evaluate 20 random ConvNet, mean = 0.0885 std = 0.0301\n",
            "-------------------------\n",
            "[2024-11-03 23:36:06] iter = 0000, loss = 218.2366\n",
            "[2024-11-03 23:37:15] iter = 0010, loss = 91.7760\n",
            "[2024-11-03 23:38:24] iter = 0020, loss = 72.9020\n",
            "[2024-11-03 23:39:33] iter = 0030, loss = 62.8031\n",
            "[2024-11-03 23:40:42] iter = 0040, loss = 53.0287\n",
            "[2024-11-03 23:41:50] iter = 0050, loss = 49.4174\n",
            "[2024-11-03 23:42:59] iter = 0060, loss = 45.8709\n",
            "[2024-11-03 23:44:08] iter = 0070, loss = 43.6740\n",
            "[2024-11-03 23:45:17] iter = 0080, loss = 41.2420\n",
            "[2024-11-03 23:46:26] iter = 0090, loss = 42.5630\n",
            "[2024-11-03 23:47:34] iter = 0100, loss = 40.2832\n",
            "[2024-11-03 23:48:43] iter = 0110, loss = 39.5130\n",
            "[2024-11-03 23:49:52] iter = 0120, loss = 39.9670\n",
            "[2024-11-03 23:51:01] iter = 0130, loss = 38.3201\n",
            "[2024-11-03 23:52:10] iter = 0140, loss = 38.5063\n",
            "[2024-11-03 23:53:18] iter = 0150, loss = 39.1595\n",
            "[2024-11-03 23:54:27] iter = 0160, loss = 36.9388\n",
            "[2024-11-03 23:55:36] iter = 0170, loss = 35.6046\n",
            "[2024-11-03 23:56:45] iter = 0180, loss = 35.6153\n",
            "[2024-11-03 23:57:54] iter = 0190, loss = 38.0057\n",
            "[2024-11-03 23:59:02] iter = 0200, loss = 37.1793\n",
            "[2024-11-04 00:00:11] iter = 0210, loss = 35.8605\n",
            "[2024-11-04 00:01:20] iter = 0220, loss = 37.4727\n",
            "[2024-11-04 00:02:29] iter = 0230, loss = 36.4194\n",
            "[2024-11-04 00:03:37] iter = 0240, loss = 36.7802\n",
            "[2024-11-04 00:04:46] iter = 0250, loss = 36.2433\n",
            "[2024-11-04 00:05:55] iter = 0260, loss = 34.1982\n",
            "[2024-11-04 00:07:03] iter = 0270, loss = 34.6914\n",
            "[2024-11-04 00:08:12] iter = 0280, loss = 35.8004\n",
            "[2024-11-04 00:09:21] iter = 0290, loss = 37.1225\n",
            "[2024-11-04 00:10:30] iter = 0300, loss = 34.3376\n",
            "[2024-11-04 00:11:39] iter = 0310, loss = 34.1631\n",
            "[2024-11-04 00:12:47] iter = 0320, loss = 37.0194\n",
            "[2024-11-04 00:13:56] iter = 0330, loss = 35.6698\n",
            "[2024-11-04 00:15:05] iter = 0340, loss = 35.5902\n",
            "[2024-11-04 00:16:14] iter = 0350, loss = 35.4962\n",
            "[2024-11-04 00:17:23] iter = 0360, loss = 35.3037\n",
            "[2024-11-04 00:18:31] iter = 0370, loss = 34.2474\n",
            "[2024-11-04 00:19:40] iter = 0380, loss = 34.9460\n",
            "[2024-11-04 00:20:49] iter = 0390, loss = 34.7055\n",
            "[2024-11-04 00:21:58] iter = 0400, loss = 33.9463\n",
            "[2024-11-04 00:23:07] iter = 0410, loss = 34.9953\n",
            "[2024-11-04 00:24:15] iter = 0420, loss = 36.0248\n",
            "[2024-11-04 00:25:24] iter = 0430, loss = 35.0337\n",
            "[2024-11-04 00:26:33] iter = 0440, loss = 33.7521\n",
            "[2024-11-04 00:27:42] iter = 0450, loss = 34.6234\n",
            "[2024-11-04 00:28:51] iter = 0460, loss = 34.3265\n",
            "[2024-11-04 00:29:59] iter = 0470, loss = 34.7398\n",
            "[2024-11-04 00:31:08] iter = 0480, loss = 34.2206\n",
            "[2024-11-04 00:32:17] iter = 0490, loss = 35.2248\n",
            "-------------------------\n",
            "Evaluation\n",
            "model_train = ConvNet, model_eval = ConvNet, iteration = 500\n",
            "DC augmentation parameters: \n",
            " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
            "[2024-11-04 00:33:56] Evaluate_00: epoch = 1000 train time = 35 s train loss = 0.013199 train acc = 1.0000, test acc = 0.9705\n",
            "[2024-11-04 00:34:34] Evaluate_01: epoch = 1000 train time = 35 s train loss = 0.019830 train acc = 1.0000, test acc = 0.9703\n",
            "[2024-11-04 00:35:12] Evaluate_02: epoch = 1000 train time = 35 s train loss = 0.010369 train acc = 1.0000, test acc = 0.9728\n",
            "[2024-11-04 00:35:50] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.014391 train acc = 1.0000, test acc = 0.9718\n",
            "[2024-11-04 00:36:27] Evaluate_04: epoch = 1000 train time = 35 s train loss = 0.011093 train acc = 1.0000, test acc = 0.9716\n",
            "[2024-11-04 00:37:05] Evaluate_05: epoch = 1000 train time = 35 s train loss = 0.017581 train acc = 1.0000, test acc = 0.9732\n",
            "[2024-11-04 00:37:43] Evaluate_06: epoch = 1000 train time = 35 s train loss = 0.011398 train acc = 1.0000, test acc = 0.9722\n",
            "[2024-11-04 00:38:20] Evaluate_07: epoch = 1000 train time = 35 s train loss = 0.009041 train acc = 1.0000, test acc = 0.9717\n",
            "[2024-11-04 00:38:58] Evaluate_08: epoch = 1000 train time = 35 s train loss = 0.014051 train acc = 1.0000, test acc = 0.9735\n",
            "[2024-11-04 00:39:36] Evaluate_09: epoch = 1000 train time = 35 s train loss = 0.021179 train acc = 1.0000, test acc = 0.9739\n",
            "[2024-11-04 00:40:14] Evaluate_10: epoch = 1000 train time = 35 s train loss = 0.013433 train acc = 1.0000, test acc = 0.9728\n",
            "[2024-11-04 00:40:51] Evaluate_11: epoch = 1000 train time = 35 s train loss = 0.016460 train acc = 1.0000, test acc = 0.9696\n",
            "[2024-11-04 00:41:29] Evaluate_12: epoch = 1000 train time = 35 s train loss = 0.007969 train acc = 1.0000, test acc = 0.9709\n",
            "[2024-11-04 00:42:07] Evaluate_13: epoch = 1000 train time = 35 s train loss = 0.012925 train acc = 1.0000, test acc = 0.9726\n",
            "[2024-11-04 00:42:44] Evaluate_14: epoch = 1000 train time = 35 s train loss = 0.020015 train acc = 1.0000, test acc = 0.9716\n",
            "[2024-11-04 00:43:22] Evaluate_15: epoch = 1000 train time = 35 s train loss = 0.009653 train acc = 1.0000, test acc = 0.9703\n",
            "[2024-11-04 00:44:00] Evaluate_16: epoch = 1000 train time = 35 s train loss = 0.011062 train acc = 1.0000, test acc = 0.9696\n",
            "[2024-11-04 00:44:37] Evaluate_17: epoch = 1000 train time = 35 s train loss = 0.014652 train acc = 1.0000, test acc = 0.9711\n",
            "[2024-11-04 00:45:15] Evaluate_18: epoch = 1000 train time = 35 s train loss = 0.015335 train acc = 1.0000, test acc = 0.9712\n",
            "[2024-11-04 00:45:53] Evaluate_19: epoch = 1000 train time = 35 s train loss = 0.009214 train acc = 1.0000, test acc = 0.9703\n",
            "Evaluate 20 random ConvNet, mean = 0.9716 std = 0.0012\n",
            "-------------------------\n",
            "[2024-11-04 00:46:00] iter = 0500, loss = 35.8609\n",
            "[2024-11-04 00:47:09] iter = 0510, loss = 35.9757\n",
            "[2024-11-04 00:48:17] iter = 0520, loss = 33.8643\n",
            "[2024-11-04 00:49:26] iter = 0530, loss = 32.5360\n",
            "[2024-11-04 00:50:34] iter = 0540, loss = 35.2380\n",
            "[2024-11-04 00:51:43] iter = 0550, loss = 34.9844\n",
            "[2024-11-04 00:52:52] iter = 0560, loss = 34.1421\n",
            "[2024-11-04 00:54:00] iter = 0570, loss = 33.5282\n",
            "[2024-11-04 00:55:09] iter = 0580, loss = 35.1536\n",
            "[2024-11-04 00:56:17] iter = 0590, loss = 33.9946\n",
            "[2024-11-04 00:57:25] iter = 0600, loss = 35.3454\n",
            "[2024-11-04 00:58:34] iter = 0610, loss = 32.9122\n",
            "[2024-11-04 00:59:43] iter = 0620, loss = 33.1043\n",
            "[2024-11-04 01:00:51] iter = 0630, loss = 34.6158\n",
            "[2024-11-04 01:02:00] iter = 0640, loss = 35.5407\n",
            "[2024-11-04 01:03:09] iter = 0650, loss = 32.7712\n",
            "[2024-11-04 01:04:18] iter = 0660, loss = 34.9927\n",
            "[2024-11-04 01:05:27] iter = 0670, loss = 33.1104\n",
            "[2024-11-04 01:06:36] iter = 0680, loss = 32.8163\n",
            "[2024-11-04 01:07:45] iter = 0690, loss = 34.3642\n",
            "[2024-11-04 01:08:54] iter = 0700, loss = 34.2557\n",
            "[2024-11-04 01:10:03] iter = 0710, loss = 34.4835\n",
            "[2024-11-04 01:11:12] iter = 0720, loss = 33.3936\n",
            "[2024-11-04 01:12:21] iter = 0730, loss = 34.2614\n",
            "[2024-11-04 01:13:30] iter = 0740, loss = 32.9793\n",
            "[2024-11-04 01:14:39] iter = 0750, loss = 34.3948\n",
            "[2024-11-04 01:15:48] iter = 0760, loss = 33.5298\n",
            "[2024-11-04 01:16:57] iter = 0770, loss = 35.3285\n",
            "[2024-11-04 01:18:05] iter = 0780, loss = 32.7962\n",
            "[2024-11-04 01:19:14] iter = 0790, loss = 34.4432\n",
            "[2024-11-04 01:20:23] iter = 0800, loss = 34.4066\n",
            "[2024-11-04 01:21:31] iter = 0810, loss = 33.1902\n",
            "[2024-11-04 01:22:40] iter = 0820, loss = 35.0239\n",
            "[2024-11-04 01:23:48] iter = 0830, loss = 34.7019\n",
            "[2024-11-04 01:24:57] iter = 0840, loss = 34.7034\n",
            "[2024-11-04 01:26:06] iter = 0850, loss = 34.9978\n",
            "[2024-11-04 01:27:15] iter = 0860, loss = 33.1920\n",
            "[2024-11-04 01:28:24] iter = 0870, loss = 32.7166\n",
            "[2024-11-04 01:29:33] iter = 0880, loss = 35.1229\n",
            "[2024-11-04 01:30:42] iter = 0890, loss = 32.6503\n",
            "[2024-11-04 01:31:51] iter = 0900, loss = 33.5469\n",
            "[2024-11-04 01:33:00] iter = 0910, loss = 35.2093\n",
            "[2024-11-04 01:34:09] iter = 0920, loss = 34.7819\n",
            "[2024-11-04 01:35:18] iter = 0930, loss = 33.6092\n",
            "[2024-11-04 01:36:26] iter = 0940, loss = 33.1600\n",
            "[2024-11-04 01:37:35] iter = 0950, loss = 32.4547\n",
            "[2024-11-04 01:38:44] iter = 0960, loss = 33.0057\n",
            "[2024-11-04 01:39:53] iter = 0970, loss = 33.9660\n",
            "[2024-11-04 01:41:01] iter = 0980, loss = 32.8017\n",
            "[2024-11-04 01:42:10] iter = 0990, loss = 33.8079\n",
            "-------------------------\n",
            "Evaluation\n",
            "model_train = ConvNet, model_eval = ConvNet, iteration = 1000\n",
            "DC augmentation parameters: \n",
            " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
            "[2024-11-04 01:43:49] Evaluate_00: epoch = 1000 train time = 35 s train loss = 0.014646 train acc = 1.0000, test acc = 0.9720\n",
            "[2024-11-04 01:44:27] Evaluate_01: epoch = 1000 train time = 35 s train loss = 0.012110 train acc = 1.0000, test acc = 0.9745\n",
            "[2024-11-04 01:45:05] Evaluate_02: epoch = 1000 train time = 35 s train loss = 0.009062 train acc = 1.0000, test acc = 0.9734\n",
            "[2024-11-04 01:45:42] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.012386 train acc = 1.0000, test acc = 0.9719\n",
            "[2024-11-04 01:46:20] Evaluate_04: epoch = 1000 train time = 35 s train loss = 0.010259 train acc = 1.0000, test acc = 0.9712\n",
            "[2024-11-04 01:46:57] Evaluate_05: epoch = 1000 train time = 35 s train loss = 0.013410 train acc = 1.0000, test acc = 0.9730\n",
            "[2024-11-04 01:47:35] Evaluate_06: epoch = 1000 train time = 35 s train loss = 0.018431 train acc = 1.0000, test acc = 0.9709\n",
            "[2024-11-04 01:48:12] Evaluate_07: epoch = 1000 train time = 35 s train loss = 0.012421 train acc = 1.0000, test acc = 0.9714\n",
            "[2024-11-04 01:48:50] Evaluate_08: epoch = 1000 train time = 35 s train loss = 0.015780 train acc = 1.0000, test acc = 0.9744\n",
            "[2024-11-04 01:49:27] Evaluate_09: epoch = 1000 train time = 35 s train loss = 0.013846 train acc = 1.0000, test acc = 0.9750\n",
            "[2024-11-04 01:50:05] Evaluate_10: epoch = 1000 train time = 35 s train loss = 0.012629 train acc = 1.0000, test acc = 0.9737\n",
            "[2024-11-04 01:50:42] Evaluate_11: epoch = 1000 train time = 35 s train loss = 0.021554 train acc = 1.0000, test acc = 0.9755\n",
            "[2024-11-04 01:51:20] Evaluate_12: epoch = 1000 train time = 35 s train loss = 0.009434 train acc = 1.0000, test acc = 0.9739\n",
            "[2024-11-04 01:51:58] Evaluate_13: epoch = 1000 train time = 35 s train loss = 0.010024 train acc = 1.0000, test acc = 0.9728\n",
            "[2024-11-04 01:52:37] Evaluate_14: epoch = 1000 train time = 35 s train loss = 0.015053 train acc = 1.0000, test acc = 0.9721\n",
            "[2024-11-04 01:53:14] Evaluate_15: epoch = 1000 train time = 35 s train loss = 0.015133 train acc = 1.0000, test acc = 0.9737\n",
            "[2024-11-04 01:53:53] Evaluate_16: epoch = 1000 train time = 35 s train loss = 0.014539 train acc = 1.0000, test acc = 0.9746\n",
            "[2024-11-04 01:54:31] Evaluate_17: epoch = 1000 train time = 35 s train loss = 0.021515 train acc = 1.0000, test acc = 0.9727\n",
            "[2024-11-04 01:55:09] Evaluate_18: epoch = 1000 train time = 35 s train loss = 0.014496 train acc = 1.0000, test acc = 0.9698\n",
            "[2024-11-04 01:55:47] Evaluate_19: epoch = 1000 train time = 35 s train loss = 0.010110 train acc = 1.0000, test acc = 0.9744\n",
            "Evaluate 20 random ConvNet, mean = 0.9730 std = 0.0015\n",
            "-------------------------\n",
            "[2024-11-04 01:55:54] iter = 1000, loss = 34.6761\n",
            "\n",
            "================== Exp 1 ==================\n",
            " \n",
            "Hyper-parameters: \n",
            " {'method': 'DM', 'dataset': 'MNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 20, 'epoch_eval_train': 1000, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7de36d1fd9c0>, 'dsa': False, 'dc_aug_param': None}\n",
            "Evaluation model pool:  ['ConvNet']\n",
            "class c = 0: 5923 real images\n",
            "class c = 1: 6742 real images\n",
            "class c = 2: 5958 real images\n",
            "class c = 3: 6131 real images\n",
            "class c = 4: 5842 real images\n",
            "class c = 5: 5421 real images\n",
            "class c = 6: 5918 real images\n",
            "class c = 7: 6265 real images\n",
            "class c = 8: 5851 real images\n",
            "class c = 9: 5949 real images\n",
            "real images channel 0, mean = -0.0001, std = 1.0000\n",
            "initialize synthetic data from random noise\n",
            "[2024-11-04 01:56:18] training begins\n",
            "-------------------------\n",
            "Evaluation\n",
            "model_train = ConvNet, model_eval = ConvNet, iteration = 0\n",
            "DC augmentation parameters: \n",
            " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
            "[2024-11-04 01:56:57] Evaluate_00: epoch = 1000 train time = 36 s train loss = 0.011602 train acc = 1.0000, test acc = 0.0998\n",
            "[2024-11-04 01:57:35] Evaluate_01: epoch = 1000 train time = 35 s train loss = 0.015881 train acc = 1.0000, test acc = 0.0710\n",
            "[2024-11-04 01:58:13] Evaluate_02: epoch = 1000 train time = 35 s train loss = 0.014815 train acc = 1.0000, test acc = 0.0923\n",
            "[2024-11-04 01:58:51] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.010866 train acc = 1.0000, test acc = 0.1252\n",
            "[2024-11-04 01:59:30] Evaluate_04: epoch = 1000 train time = 35 s train loss = 0.014343 train acc = 1.0000, test acc = 0.1045\n",
            "[2024-11-04 02:00:08] Evaluate_05: epoch = 1000 train time = 36 s train loss = 0.010073 train acc = 1.0000, test acc = 0.0887\n",
            "[2024-11-04 02:00:46] Evaluate_06: epoch = 1000 train time = 35 s train loss = 0.010539 train acc = 1.0000, test acc = 0.0933\n",
            "[2024-11-04 02:01:25] Evaluate_07: epoch = 1000 train time = 36 s train loss = 0.014053 train acc = 1.0000, test acc = 0.1459\n",
            "[2024-11-04 02:02:03] Evaluate_08: epoch = 1000 train time = 36 s train loss = 0.009953 train acc = 1.0000, test acc = 0.0550\n",
            "[2024-11-04 02:02:41] Evaluate_09: epoch = 1000 train time = 35 s train loss = 0.015632 train acc = 1.0000, test acc = 0.0593\n",
            "[2024-11-04 02:03:20] Evaluate_10: epoch = 1000 train time = 36 s train loss = 0.006588 train acc = 1.0000, test acc = 0.0798\n",
            "[2024-11-04 02:03:58] Evaluate_11: epoch = 1000 train time = 35 s train loss = 0.013626 train acc = 1.0000, test acc = 0.0858\n",
            "[2024-11-04 02:04:36] Evaluate_12: epoch = 1000 train time = 36 s train loss = 0.011831 train acc = 1.0000, test acc = 0.0784\n",
            "[2024-11-04 02:05:15] Evaluate_13: epoch = 1000 train time = 35 s train loss = 0.021772 train acc = 1.0000, test acc = 0.1237\n",
            "[2024-11-04 02:05:53] Evaluate_14: epoch = 1000 train time = 35 s train loss = 0.011416 train acc = 1.0000, test acc = 0.0793\n",
            "[2024-11-04 02:06:31] Evaluate_15: epoch = 1000 train time = 35 s train loss = 0.016215 train acc = 1.0000, test acc = 0.0830\n",
            "[2024-11-04 02:07:09] Evaluate_16: epoch = 1000 train time = 35 s train loss = 0.007074 train acc = 1.0000, test acc = 0.0985\n",
            "[2024-11-04 02:07:47] Evaluate_17: epoch = 1000 train time = 36 s train loss = 0.009493 train acc = 1.0000, test acc = 0.0755\n",
            "[2024-11-04 02:08:26] Evaluate_18: epoch = 1000 train time = 35 s train loss = 0.014739 train acc = 1.0000, test acc = 0.0828\n",
            "[2024-11-04 02:09:04] Evaluate_19: epoch = 1000 train time = 35 s train loss = 0.011253 train acc = 1.0000, test acc = 0.0720\n",
            "Evaluate 20 random ConvNet, mean = 0.0897 std = 0.0217\n",
            "-------------------------\n",
            "[2024-11-04 02:09:11] iter = 0000, loss = 219.0053\n",
            "[2024-11-04 02:10:21] iter = 0010, loss = 92.5248\n",
            "[2024-11-04 02:11:31] iter = 0020, loss = 72.5436\n",
            "[2024-11-04 02:12:41] iter = 0030, loss = 61.1474\n",
            "[2024-11-04 02:13:51] iter = 0040, loss = 56.6754\n",
            "[2024-11-04 02:15:01] iter = 0050, loss = 48.4527\n",
            "[2024-11-04 02:16:11] iter = 0060, loss = 47.3613\n",
            "[2024-11-04 02:17:21] iter = 0070, loss = 46.4235\n",
            "[2024-11-04 02:18:31] iter = 0080, loss = 42.4872\n",
            "[2024-11-04 02:19:41] iter = 0090, loss = 42.8377\n",
            "[2024-11-04 02:20:51] iter = 0100, loss = 38.8524\n",
            "[2024-11-04 02:22:00] iter = 0110, loss = 42.2304\n",
            "[2024-11-04 02:23:10] iter = 0120, loss = 39.2468\n",
            "[2024-11-04 02:24:19] iter = 0130, loss = 40.1655\n",
            "[2024-11-04 02:25:28] iter = 0140, loss = 37.1899\n",
            "[2024-11-04 02:26:37] iter = 0150, loss = 37.6837\n",
            "[2024-11-04 02:27:45] iter = 0160, loss = 38.2929\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 757, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DatasetCondensation/main.py\", line 236, in <module>\n",
            "    main()\n",
            "  File \"/content/DatasetCondensation/main.py\", line 215, in main\n",
            "    epoch('train', trainloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
            "  File \"/content/DatasetCondensation/utils.py\", line 307, in epoch\n",
            "    for i_batch, datum in enumerate(dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 697, in __next__\n",
            "    with torch.autograd.profiler.record_function(self._profile_name):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\", line 750, in __exit__\n",
            "    torch.ops.profiler._record_function_exit._RecordFunction(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 953, in __call__\n",
            "    return self._op(*args, **kwargs)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/\n"
      ],
      "metadata": {
        "id": "KqOG0Qd6BUvZ",
        "outputId": "4051eced-a706-4136-c9a4-e0034eef35b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetCondensation  drive  sample_data\n"
          ]
        }
      ]
    }
  ]
}